{
  "id": "phase3-topic4",
  "slug": "capstone",
  "name": "Improve Your Journal API",
  "description": "Time to put your AI skills to work! In this capstone, you'll revisit your Journal API from Phase 2 and improve it using everything you've learned about AI tools and prompt engineering. This isn't about adding new features\u2014it's about making what you have better.",
  "short_description": "Apply prompt engineering and AI tool skills to improve your Phase 2 Journal API prompts and code quality.",
  "order": 4,
  "estimated_time": "2-3 days",
  "is_capstone": true,
  "learning_steps": [
    {
      "order": 1,
      "text": "Review Your Current Prompts",
      "action": "Review Your Current Prompts:",
      "url": null,
      "description": "Open your Journal API from Phase 2. Find your LLM prompts and system messages. Ask yourself:\n\n\u2022 Are they clear and specific?\n\u2022 Do they use proper delimiters?\n\u2022 Do they request structured output correctly?\n\u2022 What edge cases might break them?\n\nWrite down what you find before making changes."
    },
    {
      "order": 2,
      "text": "Apply Prompt Engineering Patterns",
      "action": "Apply Prompt Engineering Patterns:",
      "url": null,
      "description": "Using what you learned, improve your prompts:\n\n1. Add clear delimiters around user content\n2. Use few-shot examples if appropriate\n3. Request structured JSON output properly\n4. Add constraints (max length, format requirements)\n5. Test with edge cases: empty entries, very long entries, entries with special characters"
    },
    {
      "order": 3,
      "text": "Use Copilot for Code Review",
      "action": "Use Copilot for Code Review:",
      "url": null,
      "description": "Select different parts of your code and ask Copilot Chat:\n\n\u2022 \"What could be improved about this error handling?\"\n\u2022 \"Are there any security concerns with this code?\"\n\u2022 \"What edge cases am I not handling?\"\n\nImplement improvements yourself based on the feedback. Don't let Copilot rewrite your code."
    },
    {
      "order": 4,
      "text": "Document Your Changes",
      "action": "Document Your Changes:",
      "url": null,
      "description": "Update your README or add comments explaining:\n\n\u2022 What prompt patterns you used and why\n\u2022 What improvements you made based on AI feedback\n\u2022 What you learned from the review process\n\nGood documentation shows you understand your own code."
    },
    {
      "order": 5,
      "text": "Reflect on Your AI Tool Usage",
      "action": "Reflect on Your AI Tool Usage:",
      "url": null,
      "description": "Write a brief reflection (can be in your README or journal):\n\n\u2022 How did AI tools help you improve your code?\n\u2022 When were you tempted to just accept AI suggestions without understanding?\n\u2022 What's the difference between how you used AI in Phase 2 vs. Phase 3?\n\u2022 How will you use AI tools going forward?"
    }
  ],
  "questions": [
    {
      "id": "phase3-topic4-q1",
      "prompt": "Walk me through the improvements you made to your Journal API prompts and the reasoning behind each change.",
      "scenario_seeds": [
        "Your original prompt was 'analyze this journal entry' and the LLM returned inconsistent formats",
        "You discovered a user could manipulate your AI analysis by including special instructions in their journal entry",
        "Your sentiment analysis worked for normal entries but failed on edge cases like empty strings or very long entries"
      ],
      "grading_rubric": "Must describe specific prompt improvements made (delimiters, structured output, few-shot examples) AND explain the reasoning behind each change AND demonstrate testing with edge cases.",
      "concepts": {
        "required": ["delimiters for security", "structured JSON output", "clear and specific instructions"],
        "expected": ["few-shot examples", "edge case testing", "format constraints"],
        "bonus": ["iterative prompt refinement process", "production-ready error handling", "prompt versioning strategy"]
      }
    },
    {
      "id": "phase3-topic4-q2",
      "prompt": "How did your approach to using AI tools evolve between Phase 2 and Phase 3?",
      "scenario_seeds": [
        "In Phase 2 you accepted most Copilot suggestions to move faster; in Phase 3 you developed a review discipline",
        "You used to paste code into ChatGPT with 'fix this' but now you ask for guiding questions",
        "Your prompts evolved from simple one-liners to structured templates with examples and constraints"
      ],
      "grading_rubric": "Must contrast Phase 2 approach (possibly uncritical acceptance) with Phase 3 discipline (understand before accepting) AND explain what changed in mindset AND demonstrate code ownership principles.",
      "concepts": {
        "required": ["accept/reject discipline", "understand before accepting", "code ownership"],
        "expected": ["AI for review not generation", "learning vs skipping", "explain-back technique"],
        "bonus": ["building long-term skills vs short-term velocity", "calibrating when to use AI assistance", "teaching others responsible AI usage"]
      }
    }
  ],
  "test_knowledge_prompts": [
    "Can you review my updated prompts and suggest further improvements?",
    "Can you quiz me on why I made specific changes to my code?",
    "Can you ask me to explain my prompt engineering decisions?"
  ],
  "learning_objectives": [
    {
      "id": "phase3-topic4-check1",
      "text": "Review and document current prompt quality",
      "order": 1
    },
    {
      "id": "phase3-topic4-check2",
      "text": "Apply prompt engineering patterns to improve prompts",
      "order": 2
    },
    {
      "id": "phase3-topic4-check3",
      "text": "Use Copilot Chat for code review (not rewriting)",
      "order": 3
    },
    {
      "id": "phase3-topic4-check4",
      "text": "Document changes and reflect on AI tool usage",
      "order": 4
    }
  ]
}
